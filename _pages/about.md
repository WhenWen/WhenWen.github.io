---
layout: about
title: About
permalink: /
subtitle: Ph.D. Student at Stanford University

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false
  more_info: >
    <p>Stanford University</p>
    <p>Stanford, CA</p>

selected_papers: true
social: true

announcements:
  enabled: true
  scrollable: true
  limit: 5

latest_posts:
  enabled: false
---

Hello! I am Kaiyue Wen. I am a second-year Ph.D. student at Stanford University, where I am grateful to be advised by [Tengyu Ma](https://ai.stanford.edu/~tengyuma/) and [Percy Liang](https://cs.stanford.edu/~pliang/). I graduated from Tsinghua University, where I was a member of Yao's pilot class. During my undergraduate study, I am fortunate to be advised by [Tengyu Ma](https://ai.stanford.edu/~tengyuma/), [Zhiyuan Liu](http://nlp.csai.tsinghua.edu.cn/~lzy/), [Andrej Risteski](https://www.andrew.cmu.edu/user/aristesk/), [Jingzhao Zhang](https://sites.google.com/view/jingzhao/home), [Yuhao Wang](https://yuhaow.github.io/) and [Zhiyuan Li](https://ai.stanford.edu/~zhiyuanli/).

My research interest spreads broadly in deep learning. My long-term goal is to understand the physics behind deep learning and I believe a combination of theoretical analysis and empirical study is essential for this goal.

Recently, I've become fascinated by two fundamental axes of scaling in deep learning.

1. **Demystifying pretraining**: Pretraining has been the driving force behind the evolution of large language models, yet many foundational algorithmic choices remain poorly understood. Key aspects such as optimizers, architectures, and hyperparameter scaling strategies still lack consensus. My goal is to clarify these choices through rigorous benchmarking (e.g., [benchmarking modern optimizers](https://arxiv.org/abs/2509.02046)) and theoretical analysis (e.g., exploring the [representation limitation of RNNs](https://arxiv.org/abs/2402.18510), [architectures beyond $\mathrm{TC}^0$](https://arxiv.org/abs/2505.16381), and [river-valley loss landscape](https://arxiv.org/abs/2410.05192)). Most of my research in this direction is carried out in the open-source project [Marin](https://marin.community/).

2. **New algorithmic paradigms in reasoning**: With the recent progress in reasoning reinforcement learning (RL), particularly innovations like long-chain-of-thought RL, there is growing potential to push the limits of model reasoning. While I am new to this field, my aim is to design end-to-end trainable multi-agent RL systems that build upon and extend the capabilities of current long-CoT RL paradigms.
